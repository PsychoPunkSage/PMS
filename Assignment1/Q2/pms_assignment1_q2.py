# -*- coding: utf-8 -*-
"""PMS_Assignment1_Q2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1INoHybCifEAblrG7wsHaoQBWVCPSXuTH

#**Question 2**

###Importing Library
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.stats import linregress

"""###Mounting Drive"""

from google.colab import drive
drive.mount('/content/drive')

ds = pd.read_excel('/content/drive/MyDrive/public/data_file.xlsx')

ds.head()

"""###Data Extraction"""

# Extracting boiling points (bp) and molecular weights (mw)
bp = ds['boiling point (K)'].values
mw = ds['molweight'].values

# Checker
print(len(bp), len(mw))

plt.scatter(mw, bp, c='red', alpha=0.7, label='Data sets', edgecolors='black', s=50)
plt.xlabel('Molecular Weight (g)', fontsize=12)
plt.ylabel('Boiling Point (K)', fontsize=12)
plt.title('Boiling Point (K) vs Molecular Weight (g)', fontsize=14)
plt.legend()
plt.grid(True, linestyle='--', alpha=0.5)

# Show the plot
plt.show()

"""###Regression Line"""

#Fitting a straight line through the data

# m -> Slope  || y -> intercept
m, y, r_value, p_value, str_err = linregress(mw, bp)
line = m*mw + y

#Regression line Plot
plt.plot(mw, line, color='green', label=f'Regression Line (R^2={r_value**2:.4f})')
plt.xlabel('Molecular Weight (g)', fontsize=12)
plt.ylabel('Boiling Point (K)', fontsize=12)
plt.title('Boiling Point (K) vs Molecular Weight (g)', fontsize=14)
plt.legend()
plt.grid(True, linestyle='--', alpha=0.5)

plt.show()

# Since rest of the question the critical temperature is of no use lets drop it.
ds = ds.drop(columns=['critical temperature (K)'])
ds = ds.drop(columns=['Unnamed: 0'])

ds.columns

ds.reset_index(drop=True, inplace=True)

def new(data):
    n = []
    for i in data:
        if isinstance(i, str):
            if i.startswith("(+)"):
                n.append(0)
            elif i.startswith("(-)"):
                n.append(1)
            else:
                n.append(0.5)
        else:
            n.append(0.5)  # Assuming a default value for non-string values

    return n

ds["name"] = new(ds["name"])

ds["name"].iloc[:10]

ds["name"] = new(ds["name"]) #### mtlb???????

ds

random_sample = ds.sample(n=100, random_state=42)

X = random_sample.iloc[:, :-1].values
y = random_sample.iloc[:, -1].values

X.shape

X

# # Assuming X is your feature matrix and y is your target vector
X_transpose = X.T  # Transpose of X

# # Check the shape of X_transpose to understand the issue
print("Shape of X_transpose:", X_transpose.shape)

# Assuming X is a feature matrix and y is a target vector

X_transpose = X.T  # Transpose of X
# Inverse of (X^T * X)
XTX_inverse = np.linalg.inv(np.dot(X_transpose, X))

# Coeffs
theta = np.dot(np.dot(XTX_inverse, X_transpose), y)

# Extracting theta values
theta0, theta1, theta2 = theta[0], theta[1], theta[2]

# Print the coefficients
print("Theta0:", theta0)
print("Theta1:", theta1)
print("Theta2:", theta2)

"""This shows that the accentric factor is more strongly correlated to the prediction of boiling point"""

y.shape

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from tensorflow import keras
from tensorflow.keras import layers

ds.columns

Input_Data = ds[['molweight', 'acentric factor']]
Target_Data = ds[['boiling point (K)']]

Input_Data.head()

Target_Data.tail()

#Splitting the dataset
X_train, X_test, y_train, y_test = train_test_split(Input_Data, Target_Data, test_size = 0.1, random_state = 42)

#Normalize the data
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

len(X_train)

len(X_test)

"""###ANN Build"""

import tensorflow as tf

# Define the model
ann = tf.keras.Sequential([
    tf.keras.layers.Dense(128, activation="relu", input_shape=(2,)),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(64, activation="relu"),
    tf.keras.layers.Dropout(0.1),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(units=1)
])

# model configure
optimizer = tf.keras.optimizers.Nadam(learning_rate=0.001)
ann.compile(loss="mse", optimizer=optimizer, metrics=["mae"])

# Train model
# Replace "features" and "labels" with your actual data
ann.fit(X_train, y_train, epochs=100, batch_size=32)

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
X_test_normalized = scaler.fit_transform(X_test)

predictions_normalized = ann.predict(X_test)

print(f"__________________________________________________________")
for i in range(5):
    prediction_value = float(predictions_normalized[i])
    actual_value = y_test.iloc[i]['boiling point (K)']
    print(f"|| Normalized Prediction : {prediction_value:.6f}, Actual: {actual_value:.4f} ||")

print(f"----------------------------------------------------------")

print("""
 _____ _                 _     __   __
|_   _| |__   __ _ _ __ | | __ \ \ / /__  _   _
  | | | '_ \ / _` | '_ \| |/ /  \ V / _ \| | | |
  | | | | | | (_| | | | |   <    | | (_) | |_| |
  |_| |_| |_|\__,_|_| |_|_|\_\   |_|\___/ \__,_|
""")