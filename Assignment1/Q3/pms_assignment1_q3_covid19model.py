# -*- coding: utf-8 -*-
"""PMS_assignment1_Q3_Covid19Model

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MLokZlpQUagPBkgOUe-mV-uFqsLTWhgV

#**Question 3**

#**A brief introduction to Epidemic(SIR) Modelling**

The SIR model, a simple mathematical representation of disease spread in a population, divides the fixed population (N individuals) into three compartments that vary with time (t):

- **S(t):** Represents individuals susceptible to the disease but not yet affected.
- **I(t):** Signifies the number of infectious individuals.
- **R(t):** Denotes individuals who have recovered from the disease and now possess immunity.

The SIR model articulates changes in each compartment's population using two parameters, β and γ. Here's a breakdown of these parameters:

- **β (effective contact rate):** Describes how frequently an infected individual comes into contact with βN other individuals per unit time. The fraction susceptible to the disease is S/N.
- **γ (mean recovery rate):** Indicates the average duration an infected individual remains contagious, with 1/γ representing the mean period during which the disease can be transmitted.
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import pandas as pd

dbd_tc_india = pd.read_excel('/content/drive/MyDrive/public/PMS/Assignment1/Q3_datasets/COVID19 India Complete Dataset May 2020.xlsx', sheet_name='Daily Cases Time-Series')
df_india = pd.read_csv('/content/drive/MyDrive/public/PMS/Assignment1/Q3_datasets/Covid cases in India.csv')

dbd_tc_india.tail()

dbd_tc_india.shape

db_india = pd.DataFrame(dbd_tc_india.groupby(['Date'])['Total Confirmed'].sum()).reset_index()

import plotly.graph_objs as go
# Assuming db_india is a Pandas DataFrame with 'Date' and 'Total Confirmed' columns
fig1 = go.Figure()
fig1.add_trace(go.Scatter(x=db_india['Date'], y=db_india['Total Confirmed'], mode='lines+markers', line=dict(color='orange', width=2), marker=dict(color='white', size=8)))

# Update layout
fig1.update_layout(
    title_text='Covid-19 Growth in India',
    xaxis_title='Date',
    yaxis_title='Total Confirmed Cases',
    xaxis_showgrid=False,
    yaxis_showgrid=False,
    width=800,
    height=500,
    font=dict(size=12, color="black"),
    plot_bgcolor='white',
    paper_bgcolor='white',
    legend=dict(font=dict(color="black")),
    margin=dict(l=10, r=10, t=40, b=10),
)

fig1.add_shape(
    go.layout.Shape(
        type="line",
        x0=db_india['Date'].iloc[0],
        x1=db_india['Date'].iloc[-1],
        y0=0,
        y1=0,
        line=dict(color="black", width=1, dash="dash"),
    )
)

fig1.update_xaxes(tickangle=-45, tickformat="%b %d %Y", showline=True, linewidth=2, linecolor='black', mirror=True)
fig1.update_yaxes(showline=True, linewidth=2, linecolor='black', mirror=True, gridcolor='grey', gridwidth=0.1)

fig1.show()

"""The curve exhibits an exponential upward trend, but the surge in the number of cases has not been as significant. Several plausible explanations could account for this:

1. **Limited Testing:** The relatively low increase might be attributed to the possibility that the number of conducted tests is significantly lower compared to other nations. A higher testing volume often correlates with the identification of more cases.

2. **Absence of Community Transmission Trigger:** It's conceivable that community transmission has not been activated in India. This could be influenced by various factors, including climatic conditions or other yet-to-be-identified variables.

3. **No Ongoing Community Transmission:** Another hypothesis is that community transmission is not occurring at present. Stringent measures, public awareness, or early detection may be contributing to the containment of community spread.

4. **Higher Immunity Levels:** The population might exhibit a higher level of immunity, either due to previous exposure to similar pathogens or other immunization factors. This increased immunity could potentially contribute to a more controlled spread of the disease.

It's important to note that these are potential explanations, and a comprehensive analysis considering various factors is necessary to gain a clearer understanding of the observed trend.

##**No. of cases in India (State-Wise)**
"""

db_state_india = pd.read_excel('/content/drive/MyDrive/public/PMS/Assignment1/Q3_datasets/COVID19 India Complete Dataset May 2020.xlsx', sheet_name='State-Wise Data')
db_state_india = db_state_india[db_state_india['State']!='Total']
db_state_india.tail()

# My state's status
jharkhand_data = db_state_india[db_state_india['State'] == 'Jharkhand']
jharkhand_data

# Plot

import plotly.express as px

# Assuming db_state_india is a Pandas DataFrame with 'State' and 'Confirmed' columns
fig = px.bar(
    db_state_india.sort_values('Confirmed', ascending=True),
    x="Confirmed",
    y="State",
    title='Total Confirmed Cases by State',
    text='Confirmed',
    orientation='h',
    width=800,
    height=800,
    range_x=[0, max(db_state_india['Confirmed'])],
)

# Update trace appearance
fig.update_traces(
    marker_color='#FF5733',
    opacity=0.8,
    textposition='inside',
    textfont=dict(color='white'),
)

# Update layout
fig.update_layout(
    plot_bgcolor='#EAEDED',
    paper_bgcolor='#EAEDED',
    font=dict(size=12, color="#333"),
    margin=dict(l=50, r=50, t=50, b=50),
    xaxis_title='Confirmed Cases',
    yaxis_title='State',
    showlegend=True,
)

# Add a horizontal line at y=0 for better clarity
fig.add_shape(
    go.layout.Shape(
        type="line",
        x0=0,
        x1=max(db_state_india['Confirmed']),
        y0=0,
        y1=0,
        line=dict(color="#333", width=1, dash="dash"),
    )
)

fig.show()

dbd_testing_india = pd.read_excel('/content/drive/MyDrive/public/PMS/Assignment1/Q3_datasets/COVID19 India Complete Dataset May 2020.xlsx', sheet_name='ICMR Testing Count')
dbd_testing_india['Update Time Stamp'] = pd.to_datetime(dbd_testing_india['Update Time Stamp'], format='%d/%m/%Y %I:%M: %p')
dbd_testing_india.tail()

df_hos_bed = dbd_testing_india.rename(columns={'Update Time Stamp':'DateTime', 'Total Individuals Tested': 'TotalIndividualsTested', 'Total Positive Cases':'TotalPositiveCases'}).copy()
df_hos_bed['DateTime'] = df_hos_bed['DateTime'].dt.date
df_hos_bed.head()

df_hos_bed['totalnegative'] = df_hos_bed['TotalIndividualsTested'] - df_hos_bed['TotalPositiveCases']

df_hos_bed_per_day = df_hos_bed.drop_duplicates(subset=['DateTime'], keep='last')
df_hos_bed_per_day['test_results_posratio'] = round(df_hos_bed_per_day['TotalPositiveCases']/df_hos_bed_per_day['TotalIndividualsTested'], 3)
df_hos_bed_per_day.head()

df_ppl =  pd.read_excel('/content/drive/MyDrive/public/PMS/Assignment1/Q3_datasets/COVID19 India Complete Dataset May 2020.xlsx', sheet_name='Raw Data')
df_ppl.rename(columns={'Patient Number': 'id', 'Current Status': 'current_status', 'Age Bracket': 'age', 'Notes': 'notes'}, inplace=True)
df_ppl.head()

detected_in_jharkhand = df_ppl[df_ppl['Detected State'] == 'Jharkhand']
detected_in_jharkhand.head()

df_ppl.dropna(subset=['current_status', 'age'], inplace=True)
df_ppl.reset_index(drop=True, inplace=True)

df_ppl['current_status'].unique()
df_ppl.shape

df1_indians = df_ppl[df_ppl['current_status']=='Deceased']
df2_indians = df_ppl[df_ppl['current_status']=='Hospitalized']
df3_indians = df_ppl[df_ppl['current_status']=='Recovered']

#Lets plot a boxplot

fig = go.Figure()
fig.add_trace(go.Box(y=df1_indians['age'], name="Deceased Patients"))
fig.add_trace(go.Box(y=df2_indians['age'], name="Hospitalized Patients"))
fig.add_trace(go.Box(y=df3_indians['age'], name="Recovered Patients"))
fig.update_layout(title_text='Indian COVID-19 Patients Outcome Age-Wise')
fig.show()

"""It's quite obvious. The older people are more vunerable to the diseases. It's also expected that the working class of the population which falls in the age range(20-40) are more affected. Along with that their recovery rate is also very high owning to their strong immune system"""

people_no_trav_his = df_ppl[df_ppl['notes'].str.contains('Travel')==False]
people_with_trav_his = df_ppl[df_ppl['notes'].str.contains('Travel')==True]

df_ppl['id'].nunique(), people_no_trav_his['id'].nunique()

negative = round(people_no_trav_his['id'].nunique() / df_ppl['id'].nunique() * 100, 2)
positive = round(people_with_trav_his['id'].nunique() / df_ppl['id'].nunique() * 100, 2)

# Custom colors
colors = ['red', 'green']

# Create a Pie chart
fig = px.pie(
    names=['Patients w/o Travel History', 'Patients with Travel History'],
    values=[negative, positive],
    title='Patients with and without Travel History',
    color_discrete_sequence=colors,
    hole=0.4,
    labels={'label': 'Travel History'},
)

# Update layout
fig.update_layout(
    font=dict(size=14, color='white'),
    paper_bgcolor='black',
    plot_bgcolor='black',
    showlegend=True,
    legend=dict(title=None, bgcolor='black', bordercolor='gray', borderwidth=1),
)

fig.show()

"""Ok thats unique!. How did people without any travel history got infected?

It may be that the close ones of people who didn't travel are people who did travel. There can be many possibilities

COVID19 Test Results In India
"""

df_ind_rate = pd.read_excel('/content/drive/MyDrive/public/PMS/Assignment1/Q3_datasets/COVID19 India Complete Dataset May 2020.xlsx', sheet_name='ICMR Testing Count')
df_ind_rate = df_ind_rate.dropna(subset=['Total Positive Cases']).reset_index(drop=True)
df_ind_rate['Total Individuals Tested'].fillna(df_ind_rate['Total Samples Tested']-900, inplace=True)
df_ind_rate['positive_percentage']=round(df_ind_rate['Total Positive Cases']/df_ind_rate['Total Individuals Tested'], 5)
df_ind_rate_count = pd.DataFrame(['India']).rename(columns={0:'Country'})
df_ind_rate_count['positive_percentage_mean'] = round(df_ind_rate.loc[len(df_ind_rate)-1]['positive_percentage']*100,2)

df_hos_bed_per_day = df_hos_bed_per_day.dropna(subset=['TotalPositiveCases']).reset_index(drop=True)
df_hos_bed_per_day['TotalIndividualsTested'].fillna(df_hos_bed_per_day['Total Samples Tested']-900, inplace=True)
df_hos_bed_per_day['test_results_posratio'] = round(df_hos_bed_per_day['TotalPositiveCases']/df_hos_bed_per_day['TotalIndividualsTested'], 3)
df_hos_bed_per_day.head(7)

fig1 = go.Figure()

fig1.add_trace(
    go.Scatter(
        x=df_hos_bed_per_day['DateTime'],
        y=df_hos_bed_per_day['test_results_posratio'] * 100,
        name='Confirmed Cases',
        marker=dict(color='#FF6F61'),
    )
)

# Update layout
fig1.update_layout(
    title_text='COVID-19 Positive Detection per Test Ratio in India w.r.t. Time',
    xaxis_showgrid=False,
    width=700,
    yaxis_title='% of Patients Tested +ve',
    height=500,
    font=dict(size=12, color="white"),
    plot_bgcolor='white',
    paper_bgcolor='black',
    showlegend=True,
    legend=dict(title=None, bgcolor='#097E99', bordercolor='gray', borderwidth=1),
)

fig1.show()

dbd_tc_india.rename(columns={'Daily Confirmed':'New Cases'}, inplace=True)
dbd_tc_india.head()

ss=[]
for i in dbd_tc_india.index:
  if(i!=min(dbd_tc_india.index)):
    lm = dbd_tc_india.loc[i]['New Cases']/dbd_tc_india.loc[i-1]['New Cases']
  else:
    lm = np.NaN
  ss.append(lm)

dbd_tc_india['Growth_Rate'] = ss
dbd_tc_india.head()

"""**Analysing the Growth Factor In India**"""

fig1 = go.Figure()
fig1.add_trace(go.Scatter(x=dbd_tc_india.iloc[35:(dbd_tc_india.shape[0]-1)]['Date'], y=dbd_tc_india.iloc[35:(dbd_tc_india.shape[0]-1)]['Growth_Rate'], name='Growth Factor', \
                         marker=dict(color='#008040')))
fig1.layout.update(title_text='COVID-19 Growth Factor in India w.r.t. Time',xaxis_showgrid=False, yaxis_showgrid=False, width=700, yaxis_title='Growth Factor',
        height=500,font=dict(
        size=12,
        color="white"
    ))
fig1.layout.plot_bgcolor = 'white'
fig1.layout.paper_bgcolor = 'white'
fig1.show()

print('Mean Growth Factor in India=', round(dbd_tc_india.iloc[35:]['Growth_Rate'].mean(), 2))

"""**SIR Epidemic Model for India**

*Note: This is a potential SIR model, if lockdown hadn't been imposed(14th March-14th April, 30 days)*
"""

#Total population, N

N=1080000 #Considering a rough estimate of 10 lakhs as population of India who might have been exposed out of 135 crore

#Initial number of infected and recovered individuals, I0 and R0.

I0, R0 = 102, 19 #till india cross 100 cases
#Everyone else, S0, is susceptible to infection initially
S0 = N - I0 - R0

#Contact rate, beta and mean recovery rate gamma, (in 1/days).

beta, gamma = 2.4, 1./35 # Considering Beta and Gamma value based on China's and Europe situation

#A grid of time points(in days)

t=np.linspace(0,30,30) # 30 values between 0 and 30

#The SIR model differential equations
def deriv(y, t, N, beta, gamma):
  S, I, R = y
  dsdt = -beta*I*S/N
  didt = beta*S*I/N-gamma*I
  drdt = gamma*I
  return dsdt, didt, drdt

#Initial conditions vector
y0 = S0, I0, R0

#Integrate the SIR equations over the time grid, t.
from scipy.integrate import odeint
ret = odeint(deriv, y0, t, args=(N, beta, gamma))
S, I, R = ret.T

# Plot the data on three separate curves for S(t), I(t) and R(t)
import matplotlib.pyplot as plt
fig = plt.figure(facecolor='w', figsize=(12, 10))
ax = fig.add_subplot(111, axisbelow=True)
ax.plot(t, S, 'b', alpha=0.5, lw=2, label='Susceptible')
ax.plot(t, I, 'r', alpha=0.5, lw=2, label='Infected')
ax.plot(t, R, 'g', alpha=0.5, lw=2, label='Recovered with immunity')
ax.set_xlabel('Time in Days', size=13)
ax.set_ylabel('Number of People', size=13)
ax.yaxis.set_tick_params(length=0)
ax.xaxis.set_tick_params(length=0)
legend = ax.legend()
ax.set_facecolor('pink')
legend.get_frame().set_alpha(0.5)
for spine in ('top', 'right', 'bottom', 'left'):
    ax.spines[spine].set_visible(False)
ax.set_title('Potential COVID-19 Scenario from 14th March for the next 30 days in India without lockdown', size=15)
plt.show()

"""Let's see if we can estimate the Beta and Gamma parameter with splitting the dataset into train and validation considering the lockdown"""

dbd_tc_india.head(2)

#Calculating total active cases
dbd_tc_param = pd. DataFrame(dbd_tc_india.groupby(['Date'])['Total Confirmed', 'Total Recovered', 'Total Deceased'].sum().reset_index())
dbd_tc_param['Total Active Cases'] = dbd_tc_param['Total Confirmed'] - dbd_tc_param['Total Recovered'] - dbd_tc_param['Total Deceased']
dbd_tc_param.head()

#Considering pre lockdown period
dbd_tc_p1 = dbd_tc_param[(dbd_tc_param['Date']>'2020-03-01') & (dbd_tc_param['Date']<'2020-03-25')].reset_index(drop=True)
dbd_tc_p1.head()

dbd_tc_param = dbd_tc_param[(dbd_tc_param['Date']>='2020-03-25')].reset_index(drop=True) #considering from lockdown date

dbd_tc_param = dbd_tc_param[:-1]
dbd_tc_param.head()

dbd_tc_param.tail()

"""Estimating Beta and Gamma for India for SIR Modelling and predicting for the next 6 months

Beta and Gamma are estimated in the following way:


*   Validation data used is from 2nd March to 24th March(pre-lockdown period) and 25th March to 19th April(lockdown period)
*  Forward prediction of 60 days have been done from 20th April considering parameter values derived during lockdown period.
* Define y(t) for the SIR model, and then use RMSE as the loss function, and used L-BFGS-B gradient descent optimzation to minimise the loss function

Pre-Lockdown Period (2nd March-25th March)

Assumptions taken:


*  An Initial population of 150000 could have been potentially exposed to COVID-19 as of 2nd March
"""

data = dbd_tc_p1.set_index('Date')['Total Active Cases'].values
infected = dbd_tc_p1.set_index('Date')['Total Confirmed'].values
recovered = dbd_tc_p1.set_index('Date')['Total Recovered'].values

s_0 = 1500000
i_0 = 5
r_0 = 3

"""Defining Loss function for estimating Beta and Gamma"""

from scipy.integrate import solve_ivp
def loss(point, data, recovered, s_0, i_0, r_0):
    size = len(data)
    beta, gamma = point
    def SIR(t, y):
        S = y[0]
        I = y[1]
        R = y[2]
        return [-beta*S*I/s_0, beta*S*I/s_0-gamma*I, gamma*I]
    solution = solve_ivp(SIR, [0, size], [s_0,i_0,r_0], t_eval=np.arange(0, size, 1), vectorized=True)
    l1 = np.sqrt(np.mean((solution.y[1] - data)**2))
    l2 = np.sqrt(np.mean((solution.y[2] - recovered)**2))
    alpha = 0.1
    return alpha * l1 + (1 - alpha) * l2

def predict(beta, gamma, data, recovered, s_0, i_0, r_0):
    size = len(data)
    new_index = np.arange(size)

    def SIR(t, y):
        S = y[0]
        I = y[1]
        R = y[2]
        return [-beta*S*I/s_0, beta*S*I/s_0-gamma*I, gamma*I]

    extended_actual = np.concatenate((data, [None] * (size - len(data))))
    extended_recovered = np.concatenate((recovered, [None] * (size - len(recovered))))

    return new_index, extended_actual, extended_recovered, solve_ivp(SIR, [0, size], [s_0,i_0,r_0], t_eval=np.arange(0, size, 1))

from scipy.optimize import minimize
def train(recovered, infected, data):
    recovered = recovered
    infected = infected
    data = data

    optimal = minimize(loss, [0.001, 0.001], args=(data, recovered, s_0, i_0, r_0), method='L-BFGS-B', bounds=[(0.00000001, 2), (0.00000001, 0.4)])
    print(optimal)

    # Extracting optimal values
    beta, gamma = optimal.x
    # Calculate R0
    r_0_calculated = beta / gamma

    new_index, extended_actual, extended_recovered, prediction = predict(beta, gamma, data, recovered, s_0, i_0, r_0)
    df = pd.DataFrame({'Actual Infected': extended_actual, 'Actual Recovered': extended_recovered, 'Susceptible': prediction.y[0], 'Predicted Infected': prediction.y[1], 'Predicted Recovered': prediction.y[2]}, index=new_index)

    fig, ax = plt.subplots(figsize=(15, 10))
    ax.set_title('Estimating Beta, Gamma and the reproduction number for India during pre-lockdown')
    df.plot(ax=ax)

    print(f"country=India, beta={beta:.8f}, gamma={gamma:.8f}, R0:{r_0_calculated:.8f}")

train(recovered, infected, data)

"""We can see for the **first wave** gave the following values
* beta(average contact rate of infection)=**0.22795005**
* gamma(average recovery rate)=**0.01424044**
* R0(which suggests when
the transmission rate is more than the recovery, R0 > 1, leads to an outbreak.):**16.00723503**

Lockdown Period (25th March-4th May)

Assumptions taken:
* An initial population of 750000 could have been potentially exposed to COVID-19 as of 25th  March
"""

dbd_tc_param.head()

dbd_tc_param.tail()

data = dbd_tc_p1.set_index('Date')['Total Active Cases']
infected = dbd_tc_p1.set_index('Date')['Total Confirmed']
recovered = dbd_tc_p1.set_index('Date')['Total Recovered']

s_0 = 750000
i_0 = 603
r_0 = 43

def loss(point, data, recovered, s_0, i_0, r_0):
    size = len(data)
    beta, gamma = point
    def SIR(t, y):
        S = y[0]
        I = y[1]
        R = y[2]
        return [-beta*S*I/s_0, beta*S*I/s_0-gamma*I, gamma*I]
    solution = solve_ivp(SIR, [0, size], [s_0,i_0,r_0], t_eval=np.arange(0, size, 1), vectorized=True)
    l1 = np.sqrt(np.mean((solution.y[1] - data)**2))
    l2 = np.sqrt(np.mean((solution.y[2] - recovered)**2))
    alpha = 0.1
    return alpha * l1 + (1 - alpha) * l2

pres_fut = np.array(list(data.index.values)+ list((np.array(pd.date_range('2020-05-05', periods=90)))))

def predict(beta, gamma, data, recovered, s_0, i_0, r_0):
    new_index = pres_fut
    size = len(new_index)
    def SIR(t, y):
        S = y[0]
        I = y[1]
        R = y[2]
        return [-beta*S*I/s_0, beta*S*I/s_0-gamma*I, gamma*I]
    extended_actual = np.concatenate((data.values, [None] * (size - len(data.values))))
    extended_recovered = np.concatenate((recovered.values, [None] * (size - len(recovered.values))))
    return new_index, extended_actual, extended_recovered, solve_ivp(SIR, [0, size], [s_0,i_0,r_0], t_eval=np.arange(0, size, 1))

def train(recovered, infected, data):
    recovered = recovered
    infected = infected
    data = data

    optimal = minimize(loss, [0.001, 0.001], args=(data, recovered, s_0, i_0, r_0), method='L-BFGS-B', bounds=[(0.00000001, 2), (0.00000001, 0.4)])
    print(optimal)

    # Extracting optimal values
    beta, gamma = optimal.x
    # Calculate R0
    r_0_calculated = beta / gamma

    new_index, extended_actual, extended_recovered, prediction = predict(beta, gamma, data, recovered, s_0, i_0, r_0)
    df = pd.DataFrame({'Actual Infected': extended_actual, 'Actual Recovered': extended_recovered, 'Susceptible': prediction.y[0], 'Predicted Infected': prediction.y[1], 'Predicted Recovered': prediction.y[2]}, index=new_index)

    fig, ax = plt.subplots(figsize=(15, 10))
    ax.set_title('Estimating Beta, Gamma and the reproduction number for India during pre-lockdown')
    df.plot(ax=ax)

    print(f"country=India, beta={beta:.8f}, gamma={gamma:.8f}, R0:{r_0_calculated:.8f}")

train(recovered, infected, data)

"""We can see for the **second wave** gave the following values
* beta(average contact rate of infection)=**0.14229311**
* gamma(average recovery rate)=**0.03901705**
* R0(which suggests when
the transmission rate is more than the recovery, R0 > 1, leads to an outbreak.):**3.64694693**

**Predicting COVID Waves using LSTM artificial recurrent neural network architecture**
"""

import seaborn as sns
from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error
import math

df = pd.read_csv('/content/drive/MyDrive/public/PMS/Assignment1/Q3_datasets/India_covid_data.csv')

df.head()

"""First I will predict the peak of third wave, and will take data upto 10th January 2022"""

df=df.iloc[:680]

df.shape

df['date'] = pd.to_datetime(df['date'], format='%d-%m-%Y')
df.tail()

df.index = df['date']
df.drop('date', axis=1, inplace=True)
df = df[['new_cases']]
df.shape

from statsmodels.tsa.stattools import adfuller

result = adfuller(df.new_cases)
print('ADF Statistic: %f' % result[0])
print('p-value: %f' % result[1])
print('Critical Values:')
for key, value in result[4].items():
 print('\t%s: %.3f' % (key, value))

df.plot(figsize=(15,6))

"""We will go ahead and normalize the data using MinMaxScaler or Standard Scaler"""

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
scaled_df = scaler.fit_transform(df)

"""**Time Series Generator**"""

from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator

length=50
generator=TimeseriesGenerator(scaled_df, scaled_df, length=length, batch_size=1)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, LSTM

model = Sequential()
#Neurons should be in the order of length of batches. Length of neurons here is 50. So we use 10 units in the first LSTM layer and increase a bit in the next layer followed by 100 again.
model.add(LSTM(10, activation='relu', input_shape=(length, 1), return_sequences=True)) #length = 50, number of features is 1('cases' column)
model.add(Dropout(0.4))

model.add(LSTM(20, activation='relu', return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(10, activation='relu', return_sequences=True))
model.add(Dense(1))
model.compile(optimizer='adam', loss='mse')

model.summary()

scaled_df

#model.save('/content/drive/MyDrive/Covid19_SIR_Model_Data/My_lstm_model.h5')

# !cp "/content/drive/MyDrive/public/PMS/Assignment1/Q3_datasets/My_lstm_model.h5" "/content/"

from tensorflow.keras.models import load_model

# Load the entire model
model = load_model("/content/drive/MyDrive/public/PMS/Assignment1/Q3_datasets/My_lstm_model.h5")

model.summary()

forecast = [] # empty list to store daily new cases forecast values
periods = 40 # days after 09-01-2022 for which we want to predict the new cases for

#length = 50 as defined earlier, we take the last 50 days (22-11-2021 till 10-1-2022) of the scaled training data to predict next day's new cases
length = 50
first_eval_batch = scaled_df[-length:]
first_eval_batch = np.array(first_eval_batch)
current_batch = first_eval_batch.reshape((1, length, 1))

#We will now use the data from the last 50 days to predict the number of cases in the new day on 11-1-2022
#Then we will drop the data from 22-11-2021 and include the data we predicted from 11-1-2022

for i in range(periods):
  current_pred = model.predict(current_batch)[0]

  #store prediction
  forecast.append(current_pred)

  #update batch to now include prediction and drop first value
  current_batch = np.append(current_batch[:,1:,:],[[current_pred]], axis=1)

forecast

forecast = scaler.inverse_transform(forecast)

forecast_index = pd.date_range(start='2022-01-09', periods=periods,freq='D')

forecast_df = pd.DataFrame(data=forecast,
                           index=forecast_index,
                           columns=['Forecast'])

forecast_df['Forecast'] = forecast_df['Forecast'].astype(int)

forecast_df.tail()

ax = df.plot(figsize=(22,12), color='green') # actual data till 10-1-2022
forecast_df.plot(ax=ax, color='red'); #predicted data from 11-01-2022 till 19-02-2022

df2 = pd.read_csv('/content/drive/MyDrive/public/PMS/Assignment1/Q3_datasets/India_covid_data.csv')
df2 = df2.iloc[:721]

df2.tail()

df2['date'] = pd.to_datetime(df2['date'], format='%d-%m-%Y')
df2.index = df2['date']
df2 = df2[['new_cases']]
df2.tail()

"""**Comparison**"""

ax = df2.plot(figsize=(22,12), color='green') #actual data till 08-02-2022
forecast_df.plot(ax=ax, color='red') # predicted data from 11-01-2022 till 19-02-2022

df2 = df2.iloc[679:719]

mse = mean_squared_error(df2, forecast_df)
print('MSE:' +str(mse))

"""**Predicting the upcoming cases now**

Now we will take cases till 30th March and we will predict the cases in Month of April

I have trained the model with this dataset. The dataset which we use to train the model previous was upto 10th jan.
"""

df3 = pd.read_csv('/content/drive/MyDrive/public/PMS/Assignment1/Q3_datasets/India_covid_data.csv')
df3['date'] = pd.to_datetime(df3['date'], format='%d-%m-%Y')
df3.index = df3['date']
df3 = df3[['new_cases']]
df3

scaler = MinMaxScaler()
scaled_df1 = scaler.fit_transform(df3)

from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator

length = 30
generator = TimeseriesGenerator(scaled_df1, scaled_df1, length=length, batch_size=1)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, LSTM

model = Sequential()
#we wants units of neurons(100 in the first LSTM layer) to be in the order of batches. length of neurons here is 50
#So we use 10 units in the first LSTM layer and increase a bit in the next layer followed by 100 again
model.add(LSTM(10, activation='relu', input_shape=(length, 1), return_sequences=True)) #length = 50, number of features is 1 ('cases' column)
model.add(Dropout(0.4))


model.add(LSTM(20, activation='relu', return_sequences=True)) #length = 50, number of features is 1 ('cases' column)
model.add(Dropout(0.2))

model.add(LSTM(10, activation='relu'))
model.add(Dropout(0.2))

model.add(Dense(1))
model.compile(optimizer='adam', loss='mse')

model.summary();

# model.save('my_lstm_model_30.h5')

forecast = [] #empty list to store daily new cases forecast values
#replace periods with whatever forecast length (day in our case) you want

periods = 40 # days after 30-03-2022 for which we want to predict the new cases for

#length = 30

first_eval_batch = scaled_df1[-length:]
current_batch = first_eval_batch.reshape((1, length, 1)) # keras expectz data batches in shape specified here. hence we need to reshape
for i in range(periods):
  #get prediction 1 time stamp ahead([0] is for grabbing just the value(eg 5) instead pf array (eg. [[5]]))
  current_pred = model.predict(current_batch)[0]
  #store prediction
  forecast.append(current_pred)
  #update batch to now include prediction and drop first value
  current_batch = np.append(current_batch[:,1:,:],[[current_pred]], axis=1)

forecast = scaler.inverse_transform(forecast)

forecast_index = pd.date_range(start='2022-03-30', periods=periods, freq='D')

forecast_df = pd.DataFrame(data=forecast, index=forecast_index, columns=['Forecast'])
forecast_df['Forecast'] = forecast_df['Forecast'].astype(int)

forecast_df.tail()

df3.tail()

ax = df3.plot(figsize=(22,12), color='yellow') #actual data till 30-3-2022
forecast_df.plot(ax=ax, color='red'); #predicted data from 30-03-2022 till 08-05-2022

df4 = pd.read_csv('/content/drive/MyDrive/public/PMS/Assignment1/Q3_datasets/India Latest case.csv', index_col='date')
df4.index = pd.to_datetime(df4.index, format='%d-%m-%Y')
df4.tail()

latest_cases = pd.concat([df3, df4], axis=0)
latest_cases.tail()

ax = latest_cases.plot(figsize=(22,12), color='yellow') #actual data till now
forecast_df.plot(ax=ax, color='red') #predicted data from 30-03-2022 till 05-08-2022

print("""
 _____ _                 _     __   __
|_   _| |__   __ _ _ __ | | __ \ \ / /__  _   _
  | | | '_ \ / _` | '_ \| |/ /  \ V / _ \| | | |
  | | | | | | (_| | | | |   <    | | (_) | |_| |
  |_| |_| |_|\__,_|_| |_|_|\_\   |_|\___/ \__,_|
""")